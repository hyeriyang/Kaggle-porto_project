{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(calc 제거).ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuL9lYSVB7oq"
      },
      "source": [
        "# 모델 학습에 필요한 라이브러리\n",
        "import lightgbm as lgbm\n",
        "import xgboost as xgb\n",
        "from scipy import sparse as ssp\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from time import time\n",
        "import datetime\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8enKZefyEAXf",
        "outputId": "ebc8208b-9d8d-45b5-da97-9da2db874cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "os.chdir('/gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAPDpvv5CO0N"
      },
      "source": [
        "def Gini(y_true, y_pred):\n",
        "    # 정답과 예측값의 개수가 동일한지 확인한다\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    n_samples = y_true.shape[0]\n",
        "\n",
        "    # 예측값(y_pred)를 오름차순으로 정렬한다\n",
        "    arr = np.array([y_true, y_pred]).transpose()\n",
        "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
        "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
        "\n",
        "    # Lorenz curves를 계산한다\n",
        "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
        "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
        "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
        "\n",
        "    # Gini 계수를 계산한다\n",
        "    G_true = np.sum(L_ones - L_true)\n",
        "    G_pred = np.sum(L_ones - L_pred)\n",
        "\n",
        "    # Gini 계수를 정규화한다\n",
        "    return G_pred * 1. / G_true\n",
        "\n",
        "# LightGBM 모델 학습 과정에서 평가 함수로 사용한다\n",
        "def evalerror(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'gini', Gini(labels, preds), True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxtcmmI-CWvH"
      },
      "source": [
        "## DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI5ZFhIcCVpO"
      },
      "source": [
        "# 훈련 데이터, 테스트 데이터를 읽어온다\n",
        "train = pd.read_csv('train.csv')\n",
        "train_label = train['target']\n",
        "train_id = train['id']\n",
        "test = pd.read_csv('test.csv')\n",
        "test_id = test['id']\n",
        "\n",
        "# target 변수를 별도로 분리하고, ‘id, target’ 변수를 제거한다. 훈련 데이터와 테스트 데이터의 변수를 동일하게 가져가기 위함이다.\n",
        "y = train['target'].values\n",
        "drop_feature = [\n",
        "    'id',\n",
        "    'target'\n",
        "]\n",
        "X = train.drop(drop_feature,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsoBn__aCi4w"
      },
      "source": [
        "## feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kut0jBmMCh51"
      },
      "source": [
        "# 범주형 변수와 수치형 변수를 분리\n",
        "# Calc 변수는 포함시키지 않음 !!!!\n",
        "feature_names = X.columns.tolist()\n",
        "cat_features = [c for c in feature_names if ('cat' in c and 'count' not in c)]\n",
        "num_features = [c for c in feature_names if ('cat' not in c and 'calc' not in c)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLqbdrzXCoK5"
      },
      "source": [
        "파생1. 결측값개수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQF_pyUBCnvM"
      },
      "source": [
        "X['missing'] = (train==-1).sum(axis=1).astype(float)\n",
        "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
        "num_features.append('missing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1GQcp-tCwZc"
      },
      "source": [
        "파생2. 범주형변수 onehotencoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyX38CSzCwE3"
      },
      "source": [
        "for c in cat_features:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(X[c])\n",
        "    X[c] = le.transform(X[c])\n",
        "    test[c] = le.transform(test[c])\n",
        "    \n",
        "enc = OneHotEncoder()\n",
        "enc.fit(X[cat_features])\n",
        "X_cat = enc.transform(X[cat_features])\n",
        "X_t_cat = enc.transform(test[cat_features])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km5PMAPHDHcS"
      },
      "source": [
        "파생3. 범주형 'new_ind' 고유값의 빈도 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdkDQvLDDDrc"
      },
      "source": [
        "#  ind 변수의 고유값을 조합한 'new ind'\n",
        "ind_features = [c for c in feature_names if 'ind' in c]\n",
        "count=0\n",
        "for c in ind_features:\n",
        "    if count==0:\n",
        "        X['new_ind'] = X[c].astype(str)+'_'\n",
        "        test['new_ind'] = test[c].astype(str)+'_'\n",
        "        count+=1\n",
        "    else:\n",
        "        X['new_ind'] += X[c].astype(str)+'_'\n",
        "        test['new_ind'] += test[c].astype(str)+'_'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viati2S3DFem"
      },
      "source": [
        "cat_count_features = []\n",
        "for c in cat_features+['new_ind']:\n",
        "    d = pd.concat([X[c],test[c]]).value_counts().to_dict()\n",
        "    X['%s_count'%c] = X[c].apply(lambda x:d.get(x,0))\n",
        "    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n",
        "    cat_count_features.append('%s_count'%c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHkXSIAYDY6C"
      },
      "source": [
        "# 수치형 변수, 범주형 변수/new_ind 빈도 및 범주형 변수를 모델 학습에 사용한다. \n",
        "train_list = [X[num_features+cat_count_features].values,X_cat,]\n",
        "test_list = [test[num_features+cat_count_features].values,X_t_cat,]\n",
        "\n",
        "# 모델 학습 속도 및 메로리 최적화를 위하여 데이터를 Sparse Matrix 형태로 변환한다.\n",
        "X = ssp.hstack(train_list).tocsr()\n",
        "X_test = ssp.hstack(test_list).tocsr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1i3JkTADcfF"
      },
      "source": [
        "## lgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtK0yCsBDbW7"
      },
      "source": [
        "# LightGBM 모델의 설정값이다.\n",
        "num_boost_round = 10000\n",
        "params = {\"objective\": \"binary\",\n",
        "          \"boosting_type\": \"gbdt\",\n",
        "          \"learning_rate\": 0.1,\n",
        "          \"num_leaves\": 15,\n",
        "           \"max_bin\": 256,\n",
        "          \"feature_fraction\": 0.6,\n",
        "          \"verbosity\": 0,\n",
        "          \"drop_rate\": 0.1,\n",
        "          \"is_unbalance\": False,\n",
        "          \"max_drop\": 50,\n",
        "          \"min_child_samples\": 10,\n",
        "          \"min_child_weight\": 150,\n",
        "          \"min_split_gain\": 0,\n",
        "          \"subsample\": 0.9\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB69bRo7DgD-"
      },
      "source": [
        "# Stratified 5-Fold 내부 교차 검증\n",
        "NFOLDS = 5\n",
        "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfk7FiUQDmVb",
        "outputId": "1994664f-5b21-4704-ac94-96cdcaa797a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_score = []\n",
        "final_cv_train = np.zeros(len(train_label))\n",
        "final_cv_pred = np.zeros(len(test_id))\n",
        "# 총20번의 다른 시드값으로 학습을 돌려, 평균값을 최종 예측 결과물로 사용한다. 시드값이 많을 수록 랜덤 요소로 인한 분산을 줄일 수 있다.\n",
        "for s in range(22):\n",
        "    cv_train = np.zeros(len(train_label))\n",
        "    cv_pred = np.zeros(len(test_id))\n",
        "\n",
        "    params['seed'] = s\n",
        "    \n",
        "    kf = kfold.split(X, train_label)\n",
        "\n",
        "    best_trees = []\n",
        "    fold_scores = []\n",
        "\n",
        "    for i, (train_fold, validate) in enumerate(kf):\n",
        "        X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n",
        "        dtrain = lgbm.Dataset(X_train, label_train)\n",
        "        dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
        "        # 훈련 데이터를 학습하고, evalerror() 함수를 통해 검증 데이터에 대한 정규화 Gini 계수 점수를 기준으로 최적의 트리 개수를 찾는다.\n",
        "        bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100, early_stopping_rounds=100)\n",
        "        best_trees.append(bst.best_iteration)\n",
        "        # 테스트 데이터에 대한 예측값을 cv_pred에 더한다.\n",
        "        cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
        "        cv_train[validate] += bst.predict(X_validate)\n",
        "\n",
        "        # 검증 데이터에 대한 평가 점수를 출력한다.\n",
        "        score = Gini(label_validate, cv_train[validate])\n",
        "        print(score)\n",
        "        fold_scores.append(score)\n",
        "\n",
        "    cv_pred /= NFOLDS\n",
        "    final_cv_train += cv_train\n",
        "    final_cv_pred += cv_pred\n",
        "\n",
        "    # 시드값별로 교차 검증 점수를 출력한다.\n",
        "    print(\"cv score:\")\n",
        "    print(Gini(train_label, cv_train))\n",
        "    print(\"current score:\", Gini(train_label, final_cv_train / (s + 1.)), s+1)\n",
        "    print(fold_scores)\n",
        "    print(best_trees, np.mean(best_trees))\n",
        "\n",
        "    x_score.append(Gini(train_label, cv_train))\n",
        "\n",
        "print(x_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15159\tvalid_0's gini: 0.291863\n",
            "[200]\tvalid_0's binary_logloss: 0.151468\tvalid_0's gini: 0.29491\n",
            "Early stopping, best iteration is:\n",
            "[189]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.295075\n",
            "0.2950745960037473\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152123\tvalid_0's gini: 0.272679\n",
            "[200]\tvalid_0's binary_logloss: 0.152038\tvalid_0's gini: 0.275581\n",
            "[300]\tvalid_0's binary_logloss: 0.152089\tvalid_0's gini: 0.276195\n",
            "Early stopping, best iteration is:\n",
            "[224]\tvalid_0's binary_logloss: 0.152015\tvalid_0's gini: 0.276851\n",
            "0.27685121636649\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151974\tvalid_0's gini: 0.277978\n",
            "[200]\tvalid_0's binary_logloss: 0.151926\tvalid_0's gini: 0.280307\n",
            "Early stopping, best iteration is:\n",
            "[139]\tvalid_0's binary_logloss: 0.151902\tvalid_0's gini: 0.280395\n",
            "0.2803950421815766\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151832\tvalid_0's gini: 0.283252\n",
            "[200]\tvalid_0's binary_logloss: 0.151762\tvalid_0's gini: 0.285428\n",
            "Early stopping, best iteration is:\n",
            "[194]\tvalid_0's binary_logloss: 0.151744\tvalid_0's gini: 0.285738\n",
            "0.2857383471455344\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151496\tvalid_0's gini: 0.288555\n",
            "[200]\tvalid_0's binary_logloss: 0.151418\tvalid_0's gini: 0.291254\n",
            "Early stopping, best iteration is:\n",
            "[183]\tvalid_0's binary_logloss: 0.151404\tvalid_0's gini: 0.291582\n",
            "0.29158193067359983\n",
            "cv score:\n",
            "0.2858393180467914\n",
            "current score: 0.2858393180467914 1\n",
            "[0.2950745960037473, 0.27685121636649, 0.2803950421815766, 0.2857383471455344, 0.29158193067359983]\n",
            "[189, 224, 139, 194, 183] 185.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151604\tvalid_0's gini: 0.290167\n",
            "[200]\tvalid_0's binary_logloss: 0.15153\tvalid_0's gini: 0.292546\n",
            "[300]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.291396\n",
            "Early stopping, best iteration is:\n",
            "[215]\tvalid_0's binary_logloss: 0.151501\tvalid_0's gini: 0.293575\n",
            "0.2935750199212115\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152153\tvalid_0's gini: 0.2722\n",
            "[200]\tvalid_0's binary_logloss: 0.152051\tvalid_0's gini: 0.27555\n",
            "Early stopping, best iteration is:\n",
            "[189]\tvalid_0's binary_logloss: 0.152041\tvalid_0's gini: 0.27574\n",
            "0.2757395481512084\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152063\tvalid_0's gini: 0.276269\n",
            "[200]\tvalid_0's binary_logloss: 0.151979\tvalid_0's gini: 0.279146\n",
            "[300]\tvalid_0's binary_logloss: 0.151971\tvalid_0's gini: 0.279805\n",
            "Early stopping, best iteration is:\n",
            "[286]\tvalid_0's binary_logloss: 0.151958\tvalid_0's gini: 0.279855\n",
            "0.2798546933254257\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151822\tvalid_0's gini: 0.284346\n",
            "[200]\tvalid_0's binary_logloss: 0.151739\tvalid_0's gini: 0.287288\n",
            "[300]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.285641\n",
            "Early stopping, best iteration is:\n",
            "[204]\tvalid_0's binary_logloss: 0.151737\tvalid_0's gini: 0.287408\n",
            "0.2874076703284102\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.290417\n",
            "[200]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.292036\n",
            "Early stopping, best iteration is:\n",
            "[165]\tvalid_0's binary_logloss: 0.151364\tvalid_0's gini: 0.292387\n",
            "0.2923866985336762\n",
            "cv score:\n",
            "0.2857025892457676\n",
            "current score: 0.2872643123582628 2\n",
            "[0.2935750199212115, 0.2757395481512084, 0.2798546933254257, 0.2874076703284102, 0.2923866985336762]\n",
            "[215, 189, 286, 204, 165] 211.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151575\tvalid_0's gini: 0.29241\n",
            "[200]\tvalid_0's binary_logloss: 0.151496\tvalid_0's gini: 0.294357\n",
            "[300]\tvalid_0's binary_logloss: 0.151506\tvalid_0's gini: 0.29466\n",
            "Early stopping, best iteration is:\n",
            "[243]\tvalid_0's binary_logloss: 0.15147\tvalid_0's gini: 0.29552\n",
            "0.2955204222194154\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152099\tvalid_0's gini: 0.275929\n",
            "[200]\tvalid_0's binary_logloss: 0.152031\tvalid_0's gini: 0.278335\n",
            "[300]\tvalid_0's binary_logloss: 0.152056\tvalid_0's gini: 0.278427\n",
            "Early stopping, best iteration is:\n",
            "[255]\tvalid_0's binary_logloss: 0.152012\tvalid_0's gini: 0.279375\n",
            "0.27937492210177034\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152058\tvalid_0's gini: 0.275752\n",
            "[200]\tvalid_0's binary_logloss: 0.152014\tvalid_0's gini: 0.278342\n",
            "Early stopping, best iteration is:\n",
            "[162]\tvalid_0's binary_logloss: 0.151987\tvalid_0's gini: 0.278225\n",
            "0.278224639267951\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151804\tvalid_0's gini: 0.284144\n",
            "[200]\tvalid_0's binary_logloss: 0.151849\tvalid_0's gini: 0.283216\n",
            "Early stopping, best iteration is:\n",
            "[137]\tvalid_0's binary_logloss: 0.151771\tvalid_0's gini: 0.285191\n",
            "0.2851906999343939\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151492\tvalid_0's gini: 0.28916\n",
            "[200]\tvalid_0's binary_logloss: 0.151414\tvalid_0's gini: 0.29076\n",
            "Early stopping, best iteration is:\n",
            "[197]\tvalid_0's binary_logloss: 0.151409\tvalid_0's gini: 0.29079\n",
            "0.290789901505339\n",
            "cv score:\n",
            "0.2857014342774277\n",
            "current score: 0.28773280818590957 3\n",
            "[0.2955204222194154, 0.27937492210177034, 0.278224639267951, 0.2851906999343939, 0.290789901505339]\n",
            "[243, 255, 162, 137, 197] 198.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151582\tvalid_0's gini: 0.2928\n",
            "[200]\tvalid_0's binary_logloss: 0.151494\tvalid_0's gini: 0.294292\n",
            "[300]\tvalid_0's binary_logloss: 0.151533\tvalid_0's gini: 0.293455\n",
            "Early stopping, best iteration is:\n",
            "[210]\tvalid_0's binary_logloss: 0.151474\tvalid_0's gini: 0.294864\n",
            "0.29486409196133345\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152092\tvalid_0's gini: 0.274761\n",
            "[200]\tvalid_0's binary_logloss: 0.152045\tvalid_0's gini: 0.276197\n",
            "Early stopping, best iteration is:\n",
            "[173]\tvalid_0's binary_logloss: 0.152026\tvalid_0's gini: 0.276538\n",
            "0.27653796783422363\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152083\tvalid_0's gini: 0.275746\n",
            "[200]\tvalid_0's binary_logloss: 0.151972\tvalid_0's gini: 0.279671\n",
            "Early stopping, best iteration is:\n",
            "[196]\tvalid_0's binary_logloss: 0.151969\tvalid_0's gini: 0.279727\n",
            "0.2797265104461791\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151804\tvalid_0's gini: 0.284287\n",
            "[200]\tvalid_0's binary_logloss: 0.151768\tvalid_0's gini: 0.285203\n",
            "Early stopping, best iteration is:\n",
            "[182]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.285923\n",
            "0.2859227849178558\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151413\tvalid_0's gini: 0.291423\n",
            "[200]\tvalid_0's binary_logloss: 0.1513\tvalid_0's gini: 0.294989\n",
            "Early stopping, best iteration is:\n",
            "[164]\tvalid_0's binary_logloss: 0.151293\tvalid_0's gini: 0.29545\n",
            "0.2954495502123637\n",
            "cv score:\n",
            "0.28642219769508487\n",
            "current score: 0.28809797959747097 4\n",
            "[0.29486409196133345, 0.27653796783422363, 0.2797265104461791, 0.2859227849178558, 0.2954495502123637]\n",
            "[210, 173, 196, 182, 164] 185.0\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151593\tvalid_0's gini: 0.291283\n",
            "[200]\tvalid_0's binary_logloss: 0.151481\tvalid_0's gini: 0.294599\n",
            "[300]\tvalid_0's binary_logloss: 0.151508\tvalid_0's gini: 0.29454\n",
            "Early stopping, best iteration is:\n",
            "[226]\tvalid_0's binary_logloss: 0.151463\tvalid_0's gini: 0.295229\n",
            "0.2952286363874112\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152107\tvalid_0's gini: 0.27518\n",
            "[200]\tvalid_0's binary_logloss: 0.152068\tvalid_0's gini: 0.277489\n",
            "Early stopping, best iteration is:\n",
            "[153]\tvalid_0's binary_logloss: 0.152021\tvalid_0's gini: 0.278142\n",
            "0.27814179935499217\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152046\tvalid_0's gini: 0.276367\n",
            "[200]\tvalid_0's binary_logloss: 0.152002\tvalid_0's gini: 0.278679\n",
            "Early stopping, best iteration is:\n",
            "[141]\tvalid_0's binary_logloss: 0.151985\tvalid_0's gini: 0.278726\n",
            "0.2787257707789949\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151801\tvalid_0's gini: 0.284706\n",
            "[200]\tvalid_0's binary_logloss: 0.151754\tvalid_0's gini: 0.286656\n",
            "Early stopping, best iteration is:\n",
            "[146]\tvalid_0's binary_logloss: 0.151743\tvalid_0's gini: 0.286936\n",
            "0.2869359770649055\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151442\tvalid_0's gini: 0.290857\n",
            "[200]\tvalid_0's binary_logloss: 0.151343\tvalid_0's gini: 0.293735\n",
            "Early stopping, best iteration is:\n",
            "[197]\tvalid_0's binary_logloss: 0.151337\tvalid_0's gini: 0.29401\n",
            "0.29401039951838737\n",
            "cv score:\n",
            "0.28657299171180295\n",
            "current score: 0.28838512642760716 5\n",
            "[0.2952286363874112, 0.27814179935499217, 0.2787257707789949, 0.2869359770649055, 0.29401039951838737]\n",
            "[226, 153, 141, 146, 197] 172.6\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151527\tvalid_0's gini: 0.29366\n",
            "[200]\tvalid_0's binary_logloss: 0.151462\tvalid_0's gini: 0.295402\n",
            "Early stopping, best iteration is:\n",
            "[190]\tvalid_0's binary_logloss: 0.151451\tvalid_0's gini: 0.295517\n",
            "0.2955173802302563\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152087\tvalid_0's gini: 0.274662\n",
            "[200]\tvalid_0's binary_logloss: 0.152011\tvalid_0's gini: 0.277844\n",
            "[300]\tvalid_0's binary_logloss: 0.1521\tvalid_0's gini: 0.276825\n",
            "Early stopping, best iteration is:\n",
            "[232]\tvalid_0's binary_logloss: 0.151991\tvalid_0's gini: 0.279094\n",
            "0.2790944965119757\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152076\tvalid_0's gini: 0.275285\n",
            "[200]\tvalid_0's binary_logloss: 0.15199\tvalid_0's gini: 0.278601\n",
            "Early stopping, best iteration is:\n",
            "[142]\tvalid_0's binary_logloss: 0.15197\tvalid_0's gini: 0.279352\n",
            "0.2793522273715637\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.1518\tvalid_0's gini: 0.283767\n",
            "[200]\tvalid_0's binary_logloss: 0.151817\tvalid_0's gini: 0.284448\n",
            "Early stopping, best iteration is:\n",
            "[157]\tvalid_0's binary_logloss: 0.151766\tvalid_0's gini: 0.285666\n",
            "0.28566634339791586\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151444\tvalid_0's gini: 0.290738\n",
            "[200]\tvalid_0's binary_logloss: 0.151397\tvalid_0's gini: 0.291561\n",
            "[300]\tvalid_0's binary_logloss: 0.151389\tvalid_0's gini: 0.292225\n",
            "Early stopping, best iteration is:\n",
            "[241]\tvalid_0's binary_logloss: 0.151365\tvalid_0's gini: 0.293066\n",
            "0.2930658556591247\n",
            "cv score:\n",
            "0.2864549941342671\n",
            "current score: 0.28857188183432725 6\n",
            "[0.2955173802302563, 0.2790944965119757, 0.2793522273715637, 0.28566634339791586, 0.2930658556591247]\n",
            "[190, 232, 142, 157, 241] 192.4\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151601\tvalid_0's gini: 0.292595\n",
            "[200]\tvalid_0's binary_logloss: 0.151564\tvalid_0's gini: 0.292948\n",
            "Early stopping, best iteration is:\n",
            "[157]\tvalid_0's binary_logloss: 0.151557\tvalid_0's gini: 0.293497\n",
            "0.2934967238620638\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152125\tvalid_0's gini: 0.274634\n",
            "[200]\tvalid_0's binary_logloss: 0.152091\tvalid_0's gini: 0.276014\n",
            "[300]\tvalid_0's binary_logloss: 0.152138\tvalid_0's gini: 0.275317\n",
            "Early stopping, best iteration is:\n",
            "[250]\tvalid_0's binary_logloss: 0.152076\tvalid_0's gini: 0.276689\n",
            "0.2766889260439311\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152069\tvalid_0's gini: 0.276395\n",
            "[200]\tvalid_0's binary_logloss: 0.151981\tvalid_0's gini: 0.279482\n",
            "Early stopping, best iteration is:\n",
            "[184]\tvalid_0's binary_logloss: 0.151975\tvalid_0's gini: 0.279621\n",
            "0.27962114975464575\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151844\tvalid_0's gini: 0.282616\n",
            "[200]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.283846\n",
            "Early stopping, best iteration is:\n",
            "[157]\tvalid_0's binary_logloss: 0.151787\tvalid_0's gini: 0.284275\n",
            "0.2842749406964166\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151533\tvalid_0's gini: 0.288513\n",
            "[200]\tvalid_0's binary_logloss: 0.151429\tvalid_0's gini: 0.291301\n",
            "Early stopping, best iteration is:\n",
            "[176]\tvalid_0's binary_logloss: 0.151425\tvalid_0's gini: 0.291478\n",
            "0.2914784981219782\n",
            "cv score:\n",
            "0.2849306183737817\n",
            "current score: 0.28846905268024015 7\n",
            "[0.2934967238620638, 0.2766889260439311, 0.27962114975464575, 0.2842749406964166, 0.2914784981219782]\n",
            "[157, 250, 184, 157, 176] 184.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151549\tvalid_0's gini: 0.292545\n",
            "[200]\tvalid_0's binary_logloss: 0.151465\tvalid_0's gini: 0.294302\n",
            "Early stopping, best iteration is:\n",
            "[177]\tvalid_0's binary_logloss: 0.151462\tvalid_0's gini: 0.294758\n",
            "0.29475795989306464\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152114\tvalid_0's gini: 0.274395\n",
            "[200]\tvalid_0's binary_logloss: 0.152046\tvalid_0's gini: 0.277096\n",
            "[300]\tvalid_0's binary_logloss: 0.15206\tvalid_0's gini: 0.277783\n",
            "Early stopping, best iteration is:\n",
            "[229]\tvalid_0's binary_logloss: 0.152002\tvalid_0's gini: 0.278437\n",
            "0.2784373625579469\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152055\tvalid_0's gini: 0.275678\n",
            "[200]\tvalid_0's binary_logloss: 0.152013\tvalid_0's gini: 0.27778\n",
            "Early stopping, best iteration is:\n",
            "[129]\tvalid_0's binary_logloss: 0.15201\tvalid_0's gini: 0.276936\n",
            "0.2769356036803868\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151814\tvalid_0's gini: 0.28414\n",
            "[200]\tvalid_0's binary_logloss: 0.151793\tvalid_0's gini: 0.284928\n",
            "Early stopping, best iteration is:\n",
            "[141]\tvalid_0's binary_logloss: 0.151768\tvalid_0's gini: 0.285197\n",
            "0.2851969005026813\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.291002\n",
            "[200]\tvalid_0's binary_logloss: 0.151314\tvalid_0's gini: 0.294441\n",
            "[300]\tvalid_0's binary_logloss: 0.151357\tvalid_0's gini: 0.293188\n",
            "Early stopping, best iteration is:\n",
            "[222]\tvalid_0's binary_logloss: 0.151313\tvalid_0's gini: 0.294627\n",
            "0.2946268999615682\n",
            "cv score:\n",
            "0.28591254303953334\n",
            "current score: 0.2885036028709306 8\n",
            "[0.29475795989306464, 0.2784373625579469, 0.2769356036803868, 0.2851969005026813, 0.2946268999615682]\n",
            "[177, 229, 129, 141, 222] 179.6\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151608\tvalid_0's gini: 0.29135\n",
            "[200]\tvalid_0's binary_logloss: 0.151545\tvalid_0's gini: 0.29309\n",
            "Early stopping, best iteration is:\n",
            "[182]\tvalid_0's binary_logloss: 0.151536\tvalid_0's gini: 0.293389\n",
            "0.2933894344716314\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152108\tvalid_0's gini: 0.274555\n",
            "[200]\tvalid_0's binary_logloss: 0.152052\tvalid_0's gini: 0.276202\n",
            "[300]\tvalid_0's binary_logloss: 0.152069\tvalid_0's gini: 0.276647\n",
            "Early stopping, best iteration is:\n",
            "[255]\tvalid_0's binary_logloss: 0.152034\tvalid_0's gini: 0.277313\n",
            "0.2773128673553526\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152087\tvalid_0's gini: 0.275393\n",
            "[200]\tvalid_0's binary_logloss: 0.152047\tvalid_0's gini: 0.277124\n",
            "Early stopping, best iteration is:\n",
            "[129]\tvalid_0's binary_logloss: 0.152039\tvalid_0's gini: 0.277116\n",
            "0.27711602276102837\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151775\tvalid_0's gini: 0.285865\n",
            "[200]\tvalid_0's binary_logloss: 0.151751\tvalid_0's gini: 0.286686\n",
            "Early stopping, best iteration is:\n",
            "[166]\tvalid_0's binary_logloss: 0.151725\tvalid_0's gini: 0.287102\n",
            "0.28710240787255004\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151478\tvalid_0's gini: 0.289751\n",
            "[200]\tvalid_0's binary_logloss: 0.151422\tvalid_0's gini: 0.290651\n",
            "Early stopping, best iteration is:\n",
            "[164]\tvalid_0's binary_logloss: 0.151427\tvalid_0's gini: 0.291024\n",
            "0.2910241608237578\n",
            "cv score:\n",
            "0.2850760894090657\n",
            "current score: 0.28843619017397537 9\n",
            "[0.2933894344716314, 0.2773128673553526, 0.27711602276102837, 0.28710240787255004, 0.2910241608237578]\n",
            "[182, 255, 129, 166, 164] 179.2\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151548\tvalid_0's gini: 0.292315\n",
            "[200]\tvalid_0's binary_logloss: 0.151452\tvalid_0's gini: 0.294847\n",
            "[300]\tvalid_0's binary_logloss: 0.151454\tvalid_0's gini: 0.295291\n",
            "Early stopping, best iteration is:\n",
            "[239]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.295568\n",
            "0.2955676674856543\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152158\tvalid_0's gini: 0.273093\n",
            "[200]\tvalid_0's binary_logloss: 0.152089\tvalid_0's gini: 0.276147\n",
            "Early stopping, best iteration is:\n",
            "[196]\tvalid_0's binary_logloss: 0.152079\tvalid_0's gini: 0.276243\n",
            "0.276242645740053\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152047\tvalid_0's gini: 0.276454\n",
            "[200]\tvalid_0's binary_logloss: 0.151962\tvalid_0's gini: 0.280027\n",
            "[300]\tvalid_0's binary_logloss: 0.151985\tvalid_0's gini: 0.279929\n",
            "Early stopping, best iteration is:\n",
            "[212]\tvalid_0's binary_logloss: 0.151938\tvalid_0's gini: 0.280751\n",
            "0.2807507596195159\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151818\tvalid_0's gini: 0.283789\n",
            "[200]\tvalid_0's binary_logloss: 0.15181\tvalid_0's gini: 0.284446\n",
            "[300]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.285261\n",
            "Early stopping, best iteration is:\n",
            "[248]\tvalid_0's binary_logloss: 0.15179\tvalid_0's gini: 0.285349\n",
            "0.2853491740827971\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.287214\n",
            "[200]\tvalid_0's binary_logloss: 0.151501\tvalid_0's gini: 0.288273\n",
            "Early stopping, best iteration is:\n",
            "[149]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.289234\n",
            "0.28923363521695494\n",
            "cv score:\n",
            "0.28534116886916905\n",
            "current score: 0.28844964503270565 10\n",
            "[0.2955676674856543, 0.276242645740053, 0.2807507596195159, 0.2853491740827971, 0.28923363521695494]\n",
            "[239, 196, 212, 248, 149] 208.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151545\tvalid_0's gini: 0.292477\n",
            "[200]\tvalid_0's binary_logloss: 0.151517\tvalid_0's gini: 0.293056\n",
            "Early stopping, best iteration is:\n",
            "[177]\tvalid_0's binary_logloss: 0.151498\tvalid_0's gini: 0.293759\n",
            "0.29375880911035007\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152093\tvalid_0's gini: 0.274525\n",
            "[200]\tvalid_0's binary_logloss: 0.151989\tvalid_0's gini: 0.278548\n",
            "[300]\tvalid_0's binary_logloss: 0.152041\tvalid_0's gini: 0.278658\n",
            "Early stopping, best iteration is:\n",
            "[225]\tvalid_0's binary_logloss: 0.151977\tvalid_0's gini: 0.279613\n",
            "0.27961328626418364\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152074\tvalid_0's gini: 0.27583\n",
            "[200]\tvalid_0's binary_logloss: 0.152013\tvalid_0's gini: 0.278264\n",
            "[300]\tvalid_0's binary_logloss: 0.152015\tvalid_0's gini: 0.278326\n",
            "Early stopping, best iteration is:\n",
            "[258]\tvalid_0's binary_logloss: 0.151993\tvalid_0's gini: 0.278944\n",
            "0.2789441772664835\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151819\tvalid_0's gini: 0.283863\n",
            "[200]\tvalid_0's binary_logloss: 0.151833\tvalid_0's gini: 0.284569\n",
            "Early stopping, best iteration is:\n",
            "[116]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.283995\n",
            "0.2839952601055715\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151509\tvalid_0's gini: 0.287653\n",
            "[200]\tvalid_0's binary_logloss: 0.15141\tvalid_0's gini: 0.290869\n",
            "[300]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.289624\n",
            "Early stopping, best iteration is:\n",
            "[204]\tvalid_0's binary_logloss: 0.151402\tvalid_0's gini: 0.291042\n",
            "0.2910419106034895\n",
            "cv score:\n",
            "0.28532266076273827\n",
            "current score: 0.2884465453452323 11\n",
            "[0.29375880911035007, 0.27961328626418364, 0.2789441772664835, 0.2839952601055715, 0.2910419106034895]\n",
            "[177, 225, 258, 116, 204] 196.0\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151543\tvalid_0's gini: 0.293201\n",
            "[200]\tvalid_0's binary_logloss: 0.151467\tvalid_0's gini: 0.295595\n",
            "Early stopping, best iteration is:\n",
            "[154]\tvalid_0's binary_logloss: 0.15144\tvalid_0's gini: 0.295968\n",
            "0.2959683782293427\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152227\tvalid_0's gini: 0.271808\n",
            "[200]\tvalid_0's binary_logloss: 0.152133\tvalid_0's gini: 0.275909\n",
            "[300]\tvalid_0's binary_logloss: 0.152186\tvalid_0's gini: 0.276224\n",
            "Early stopping, best iteration is:\n",
            "[218]\tvalid_0's binary_logloss: 0.152119\tvalid_0's gini: 0.276549\n",
            "0.27654868110119585\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152017\tvalid_0's gini: 0.277246\n",
            "[200]\tvalid_0's binary_logloss: 0.151937\tvalid_0's gini: 0.280069\n",
            "Early stopping, best iteration is:\n",
            "[198]\tvalid_0's binary_logloss: 0.151935\tvalid_0's gini: 0.280143\n",
            "0.2801430696339272\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151803\tvalid_0's gini: 0.28397\n",
            "[200]\tvalid_0's binary_logloss: 0.151783\tvalid_0's gini: 0.285072\n",
            "Early stopping, best iteration is:\n",
            "[171]\tvalid_0's binary_logloss: 0.151753\tvalid_0's gini: 0.285496\n",
            "0.2854960789271823\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.290377\n",
            "[200]\tvalid_0's binary_logloss: 0.151374\tvalid_0's gini: 0.293165\n",
            "Early stopping, best iteration is:\n",
            "[158]\tvalid_0's binary_logloss: 0.151373\tvalid_0's gini: 0.29336\n",
            "0.2933600671993721\n",
            "cv score:\n",
            "0.28618096957698835\n",
            "current score: 0.2885010259332192 12\n",
            "[0.2959683782293427, 0.27654868110119585, 0.2801430696339272, 0.2854960789271823, 0.2933600671993721]\n",
            "[154, 218, 198, 171, 158] 179.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151549\tvalid_0's gini: 0.29324\n",
            "[200]\tvalid_0's binary_logloss: 0.151445\tvalid_0's gini: 0.2965\n",
            "[300]\tvalid_0's binary_logloss: 0.151467\tvalid_0's gini: 0.295659\n",
            "Early stopping, best iteration is:\n",
            "[212]\tvalid_0's binary_logloss: 0.151433\tvalid_0's gini: 0.296886\n",
            "0.2968862592779062\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152137\tvalid_0's gini: 0.273446\n",
            "[200]\tvalid_0's binary_logloss: 0.152054\tvalid_0's gini: 0.276994\n",
            "Early stopping, best iteration is:\n",
            "[194]\tvalid_0's binary_logloss: 0.152043\tvalid_0's gini: 0.277307\n",
            "0.2773070405597376\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152119\tvalid_0's gini: 0.274704\n",
            "[200]\tvalid_0's binary_logloss: 0.152005\tvalid_0's gini: 0.278497\n",
            "Early stopping, best iteration is:\n",
            "[198]\tvalid_0's binary_logloss: 0.151999\tvalid_0's gini: 0.278625\n",
            "0.2786247309489958\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151822\tvalid_0's gini: 0.284249\n",
            "[200]\tvalid_0's binary_logloss: 0.151776\tvalid_0's gini: 0.28493\n",
            "Early stopping, best iteration is:\n",
            "[155]\tvalid_0's binary_logloss: 0.151772\tvalid_0's gini: 0.285764\n",
            "0.2857639290105496\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15151\tvalid_0's gini: 0.287782\n",
            "[200]\tvalid_0's binary_logloss: 0.151392\tvalid_0's gini: 0.291393\n",
            "Early stopping, best iteration is:\n",
            "[190]\tvalid_0's binary_logloss: 0.151386\tvalid_0's gini: 0.291615\n",
            "0.291615039216776\n",
            "cv score:\n",
            "0.2859750728807769\n",
            "current score: 0.28851836010314574 13\n",
            "[0.2968862592779062, 0.2773070405597376, 0.2786247309489958, 0.2857639290105496, 0.291615039216776]\n",
            "[212, 194, 198, 155, 190] 189.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151548\tvalid_0's gini: 0.293495\n",
            "[200]\tvalid_0's binary_logloss: 0.151433\tvalid_0's gini: 0.296269\n",
            "[300]\tvalid_0's binary_logloss: 0.151436\tvalid_0's gini: 0.295894\n",
            "Early stopping, best iteration is:\n",
            "[237]\tvalid_0's binary_logloss: 0.151419\tvalid_0's gini: 0.296735\n",
            "0.29673532116059737\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152149\tvalid_0's gini: 0.272677\n",
            "[200]\tvalid_0's binary_logloss: 0.152083\tvalid_0's gini: 0.27552\n",
            "[300]\tvalid_0's binary_logloss: 0.152116\tvalid_0's gini: 0.275927\n",
            "Early stopping, best iteration is:\n",
            "[239]\tvalid_0's binary_logloss: 0.152064\tvalid_0's gini: 0.276679\n",
            "0.27667851014445916\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152087\tvalid_0's gini: 0.276195\n",
            "[200]\tvalid_0's binary_logloss: 0.151996\tvalid_0's gini: 0.279471\n",
            "Early stopping, best iteration is:\n",
            "[188]\tvalid_0's binary_logloss: 0.151977\tvalid_0's gini: 0.280084\n",
            "0.28008369094793084\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151821\tvalid_0's gini: 0.284589\n",
            "[200]\tvalid_0's binary_logloss: 0.151836\tvalid_0's gini: 0.284824\n",
            "Early stopping, best iteration is:\n",
            "[131]\tvalid_0's binary_logloss: 0.151767\tvalid_0's gini: 0.28618\n",
            "0.28617958408561006\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151454\tvalid_0's gini: 0.290433\n",
            "[200]\tvalid_0's binary_logloss: 0.151403\tvalid_0's gini: 0.292204\n",
            "Early stopping, best iteration is:\n",
            "[157]\tvalid_0's binary_logloss: 0.151387\tvalid_0's gini: 0.292099\n",
            "0.29209911754279666\n",
            "cv score:\n",
            "0.28622141629497744\n",
            "current score: 0.2885596390091784 14\n",
            "[0.29673532116059737, 0.27667851014445916, 0.28008369094793084, 0.28617958408561006, 0.29209911754279666]\n",
            "[237, 239, 188, 131, 157] 190.4\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151518\tvalid_0's gini: 0.294144\n",
            "[200]\tvalid_0's binary_logloss: 0.151461\tvalid_0's gini: 0.295541\n",
            "Early stopping, best iteration is:\n",
            "[148]\tvalid_0's binary_logloss: 0.151463\tvalid_0's gini: 0.295874\n",
            "0.2958735461260875\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152109\tvalid_0's gini: 0.274049\n",
            "[200]\tvalid_0's binary_logloss: 0.152067\tvalid_0's gini: 0.275319\n",
            "[300]\tvalid_0's binary_logloss: 0.152101\tvalid_0's gini: 0.275549\n",
            "Early stopping, best iteration is:\n",
            "[240]\tvalid_0's binary_logloss: 0.152032\tvalid_0's gini: 0.27689\n",
            "0.27688973751322515\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15212\tvalid_0's gini: 0.274505\n",
            "[200]\tvalid_0's binary_logloss: 0.152001\tvalid_0's gini: 0.279239\n",
            "[300]\tvalid_0's binary_logloss: 0.152056\tvalid_0's gini: 0.278137\n",
            "Early stopping, best iteration is:\n",
            "[219]\tvalid_0's binary_logloss: 0.151992\tvalid_0's gini: 0.279543\n",
            "0.27954340238287106\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151841\tvalid_0's gini: 0.283119\n",
            "[200]\tvalid_0's binary_logloss: 0.151845\tvalid_0's gini: 0.283338\n",
            "Early stopping, best iteration is:\n",
            "[154]\tvalid_0's binary_logloss: 0.151786\tvalid_0's gini: 0.285047\n",
            "0.2850468813093507\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151476\tvalid_0's gini: 0.290042\n",
            "[200]\tvalid_0's binary_logloss: 0.151407\tvalid_0's gini: 0.291736\n",
            "[300]\tvalid_0's binary_logloss: 0.151469\tvalid_0's gini: 0.290186\n",
            "Early stopping, best iteration is:\n",
            "[207]\tvalid_0's binary_logloss: 0.151405\tvalid_0's gini: 0.291903\n",
            "0.29190300598507335\n",
            "cv score:\n",
            "0.2856714472163492\n",
            "current score: 0.2885496480909848 15\n",
            "[0.2958735461260875, 0.27688973751322515, 0.27954340238287106, 0.2850468813093507, 0.29190300598507335]\n",
            "[148, 240, 219, 154, 207] 193.6\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151601\tvalid_0's gini: 0.292096\n",
            "[200]\tvalid_0's binary_logloss: 0.151496\tvalid_0's gini: 0.294731\n",
            "Early stopping, best iteration is:\n",
            "[197]\tvalid_0's binary_logloss: 0.151489\tvalid_0's gini: 0.294925\n",
            "0.29492506837282534\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152046\tvalid_0's gini: 0.276157\n",
            "[200]\tvalid_0's binary_logloss: 0.151952\tvalid_0's gini: 0.279624\n",
            "Early stopping, best iteration is:\n",
            "[192]\tvalid_0's binary_logloss: 0.151945\tvalid_0's gini: 0.279831\n",
            "0.2798313410300186\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152063\tvalid_0's gini: 0.275495\n",
            "[200]\tvalid_0's binary_logloss: 0.151991\tvalid_0's gini: 0.27821\n",
            "[300]\tvalid_0's binary_logloss: 0.152031\tvalid_0's gini: 0.277822\n",
            "Early stopping, best iteration is:\n",
            "[229]\tvalid_0's binary_logloss: 0.15197\tvalid_0's gini: 0.278833\n",
            "0.27883290402860883\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151816\tvalid_0's gini: 0.284155\n",
            "[200]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.284813\n",
            "Early stopping, best iteration is:\n",
            "[151]\tvalid_0's binary_logloss: 0.151794\tvalid_0's gini: 0.284781\n",
            "0.2847811288906925\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151512\tvalid_0's gini: 0.28849\n",
            "[200]\tvalid_0's binary_logloss: 0.151469\tvalid_0's gini: 0.290052\n",
            "Early stopping, best iteration is:\n",
            "[144]\tvalid_0's binary_logloss: 0.151453\tvalid_0's gini: 0.290385\n",
            "0.2903850321239166\n",
            "cv score:\n",
            "0.2856285709657942\n",
            "current score: 0.28854785993958426 16\n",
            "[0.29492506837282534, 0.2798313410300186, 0.27883290402860883, 0.2847811288906925, 0.2903850321239166]\n",
            "[197, 192, 229, 151, 144] 182.6\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151553\tvalid_0's gini: 0.292178\n",
            "[200]\tvalid_0's binary_logloss: 0.151466\tvalid_0's gini: 0.294433\n",
            "[300]\tvalid_0's binary_logloss: 0.151483\tvalid_0's gini: 0.294528\n",
            "Early stopping, best iteration is:\n",
            "[264]\tvalid_0's binary_logloss: 0.151445\tvalid_0's gini: 0.29515\n",
            "0.295149757648702\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152189\tvalid_0's gini: 0.272652\n",
            "[200]\tvalid_0's binary_logloss: 0.152091\tvalid_0's gini: 0.276103\n",
            "Early stopping, best iteration is:\n",
            "[172]\tvalid_0's binary_logloss: 0.152074\tvalid_0's gini: 0.276876\n",
            "0.2768755201319245\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152003\tvalid_0's gini: 0.277212\n",
            "[200]\tvalid_0's binary_logloss: 0.151942\tvalid_0's gini: 0.279495\n",
            "[300]\tvalid_0's binary_logloss: 0.151949\tvalid_0's gini: 0.280333\n",
            "Early stopping, best iteration is:\n",
            "[232]\tvalid_0's binary_logloss: 0.151918\tvalid_0's gini: 0.280425\n",
            "0.28042480990299334\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151811\tvalid_0's gini: 0.284418\n",
            "[200]\tvalid_0's binary_logloss: 0.151799\tvalid_0's gini: 0.284687\n",
            "Early stopping, best iteration is:\n",
            "[165]\tvalid_0's binary_logloss: 0.151772\tvalid_0's gini: 0.285531\n",
            "0.28553113243150635\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151442\tvalid_0's gini: 0.290372\n",
            "[200]\tvalid_0's binary_logloss: 0.151397\tvalid_0's gini: 0.291633\n",
            "Early stopping, best iteration is:\n",
            "[130]\tvalid_0's binary_logloss: 0.151392\tvalid_0's gini: 0.291626\n",
            "0.29162587715110605\n",
            "cv score:\n",
            "0.2858530956858175\n",
            "current score: 0.28857182573356865 17\n",
            "[0.295149757648702, 0.2768755201319245, 0.28042480990299334, 0.28553113243150635, 0.29162587715110605]\n",
            "[264, 172, 232, 165, 130] 192.6\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151603\tvalid_0's gini: 0.291972\n",
            "[200]\tvalid_0's binary_logloss: 0.151531\tvalid_0's gini: 0.293617\n",
            "Early stopping, best iteration is:\n",
            "[190]\tvalid_0's binary_logloss: 0.151513\tvalid_0's gini: 0.293963\n",
            "0.2939629800287022\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152093\tvalid_0's gini: 0.275053\n",
            "[200]\tvalid_0's binary_logloss: 0.152027\tvalid_0's gini: 0.277382\n",
            "[300]\tvalid_0's binary_logloss: 0.15209\tvalid_0's gini: 0.276238\n",
            "Early stopping, best iteration is:\n",
            "[208]\tvalid_0's binary_logloss: 0.152014\tvalid_0's gini: 0.277835\n",
            "0.27783516925884866\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152052\tvalid_0's gini: 0.276478\n",
            "[200]\tvalid_0's binary_logloss: 0.151956\tvalid_0's gini: 0.280293\n",
            "[300]\tvalid_0's binary_logloss: 0.151958\tvalid_0's gini: 0.2808\n",
            "Early stopping, best iteration is:\n",
            "[284]\tvalid_0's binary_logloss: 0.151937\tvalid_0's gini: 0.28111\n",
            "0.2811102552991688\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151801\tvalid_0's gini: 0.284409\n",
            "[200]\tvalid_0's binary_logloss: 0.151772\tvalid_0's gini: 0.284913\n",
            "Early stopping, best iteration is:\n",
            "[175]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.285538\n",
            "0.2855382532396758\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.290289\n",
            "[200]\tvalid_0's binary_logloss: 0.151385\tvalid_0's gini: 0.291665\n",
            "Early stopping, best iteration is:\n",
            "[177]\tvalid_0's binary_logloss: 0.151354\tvalid_0's gini: 0.292548\n",
            "0.2925482146977591\n",
            "cv score:\n",
            "0.2860702512738158\n",
            "current score: 0.2886003736253298 18\n",
            "[0.2939629800287022, 0.27783516925884866, 0.2811102552991688, 0.2855382532396758, 0.2925482146977591]\n",
            "[190, 208, 284, 175, 177] 206.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151506\tvalid_0's gini: 0.295123\n",
            "[200]\tvalid_0's binary_logloss: 0.151442\tvalid_0's gini: 0.296382\n",
            "[300]\tvalid_0's binary_logloss: 0.15148\tvalid_0's gini: 0.294979\n",
            "Early stopping, best iteration is:\n",
            "[217]\tvalid_0's binary_logloss: 0.151431\tvalid_0's gini: 0.296701\n",
            "0.29670081045663715\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152091\tvalid_0's gini: 0.273873\n",
            "[200]\tvalid_0's binary_logloss: 0.152027\tvalid_0's gini: 0.276082\n",
            "Early stopping, best iteration is:\n",
            "[181]\tvalid_0's binary_logloss: 0.152021\tvalid_0's gini: 0.276363\n",
            "0.276362625489487\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15215\tvalid_0's gini: 0.273249\n",
            "[200]\tvalid_0's binary_logloss: 0.15204\tvalid_0's gini: 0.277479\n",
            "Early stopping, best iteration is:\n",
            "[185]\tvalid_0's binary_logloss: 0.152034\tvalid_0's gini: 0.277521\n",
            "0.277520612157475\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.284216\n",
            "[200]\tvalid_0's binary_logloss: 0.151805\tvalid_0's gini: 0.284355\n",
            "Early stopping, best iteration is:\n",
            "[161]\tvalid_0's binary_logloss: 0.151753\tvalid_0's gini: 0.285778\n",
            "0.28577776877541156\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151497\tvalid_0's gini: 0.289024\n",
            "[200]\tvalid_0's binary_logloss: 0.15141\tvalid_0's gini: 0.29114\n",
            "Early stopping, best iteration is:\n",
            "[170]\tvalid_0's binary_logloss: 0.151381\tvalid_0's gini: 0.292328\n",
            "0.2923277348664808\n",
            "cv score:\n",
            "0.28565408652314167\n",
            "current score: 0.2885892966993273 19\n",
            "[0.29670081045663715, 0.276362625489487, 0.277520612157475, 0.28577776877541156, 0.2923277348664808]\n",
            "[217, 181, 185, 161, 170] 182.8\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151557\tvalid_0's gini: 0.293018\n",
            "[200]\tvalid_0's binary_logloss: 0.151504\tvalid_0's gini: 0.293611\n",
            "Early stopping, best iteration is:\n",
            "[148]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.294971\n",
            "0.29497115229842086\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152146\tvalid_0's gini: 0.27266\n",
            "[200]\tvalid_0's binary_logloss: 0.15211\tvalid_0's gini: 0.275177\n",
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's binary_logloss: 0.15208\tvalid_0's gini: 0.275745\n",
            "0.2757449570249311\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152094\tvalid_0's gini: 0.275375\n",
            "[200]\tvalid_0's binary_logloss: 0.152022\tvalid_0's gini: 0.278011\n",
            "[300]\tvalid_0's binary_logloss: 0.152024\tvalid_0's gini: 0.27823\n",
            "Early stopping, best iteration is:\n",
            "[256]\tvalid_0's binary_logloss: 0.151987\tvalid_0's gini: 0.27925\n",
            "0.279250439932034\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15176\tvalid_0's gini: 0.285835\n",
            "[200]\tvalid_0's binary_logloss: 0.151679\tvalid_0's gini: 0.287953\n",
            "Early stopping, best iteration is:\n",
            "[153]\tvalid_0's binary_logloss: 0.151659\tvalid_0's gini: 0.288521\n",
            "0.28852081097477755\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151421\tvalid_0's gini: 0.290363\n",
            "[200]\tvalid_0's binary_logloss: 0.151399\tvalid_0's gini: 0.291018\n",
            "Early stopping, best iteration is:\n",
            "[142]\tvalid_0's binary_logloss: 0.151368\tvalid_0's gini: 0.291592\n",
            "0.29159191668279905\n",
            "cv score:\n",
            "0.28588450841345214\n",
            "current score: 0.288598963551248 20\n",
            "[0.29497115229842086, 0.2757449570249311, 0.279250439932034, 0.28852081097477755, 0.29159191668279905]\n",
            "[148, 174, 256, 153, 142] 174.6\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151607\tvalid_0's gini: 0.291832\n",
            "[200]\tvalid_0's binary_logloss: 0.151532\tvalid_0's gini: 0.293776\n",
            "Early stopping, best iteration is:\n",
            "[174]\tvalid_0's binary_logloss: 0.151507\tvalid_0's gini: 0.294194\n",
            "0.29419449268316816\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15216\tvalid_0's gini: 0.272652\n",
            "[200]\tvalid_0's binary_logloss: 0.15215\tvalid_0's gini: 0.273725\n",
            "Early stopping, best iteration is:\n",
            "[148]\tvalid_0's binary_logloss: 0.15212\tvalid_0's gini: 0.273724\n",
            "0.2737239791783597\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15213\tvalid_0's gini: 0.2737\n",
            "[200]\tvalid_0's binary_logloss: 0.152\tvalid_0's gini: 0.27854\n",
            "Early stopping, best iteration is:\n",
            "[169]\tvalid_0's binary_logloss: 0.151985\tvalid_0's gini: 0.279023\n",
            "0.2790232349646397\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151806\tvalid_0's gini: 0.284873\n",
            "[200]\tvalid_0's binary_logloss: 0.151791\tvalid_0's gini: 0.285005\n",
            "Early stopping, best iteration is:\n",
            "[171]\tvalid_0's binary_logloss: 0.151758\tvalid_0's gini: 0.285692\n",
            "0.2856923431884668\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151475\tvalid_0's gini: 0.28907\n",
            "[200]\tvalid_0's binary_logloss: 0.151408\tvalid_0's gini: 0.291549\n",
            "[300]\tvalid_0's binary_logloss: 0.15145\tvalid_0's gini: 0.290751\n",
            "Early stopping, best iteration is:\n",
            "[254]\tvalid_0's binary_logloss: 0.151403\tvalid_0's gini: 0.292058\n",
            "0.2920583577475016\n",
            "cv score:\n",
            "0.28487583381291626\n",
            "current score: 0.2885777203319014 21\n",
            "[0.29419449268316816, 0.2737239791783597, 0.2790232349646397, 0.2856923431884668, 0.2920583577475016]\n",
            "[174, 148, 169, 171, 254] 183.2\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151512\tvalid_0's gini: 0.294079\n",
            "[200]\tvalid_0's binary_logloss: 0.151482\tvalid_0's gini: 0.294703\n",
            "[300]\tvalid_0's binary_logloss: 0.151501\tvalid_0's gini: 0.294364\n",
            "Early stopping, best iteration is:\n",
            "[208]\tvalid_0's binary_logloss: 0.151466\tvalid_0's gini: 0.295059\n",
            "0.29505891187734334\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.152134\tvalid_0's gini: 0.274795\n",
            "[200]\tvalid_0's binary_logloss: 0.15204\tvalid_0's gini: 0.277648\n",
            "[300]\tvalid_0's binary_logloss: 0.152049\tvalid_0's gini: 0.277832\n",
            "Early stopping, best iteration is:\n",
            "[258]\tvalid_0's binary_logloss: 0.152021\tvalid_0's gini: 0.278142\n",
            "0.2781424423117497\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.15208\tvalid_0's gini: 0.275457\n",
            "[200]\tvalid_0's binary_logloss: 0.152019\tvalid_0's gini: 0.278213\n",
            "[300]\tvalid_0's binary_logloss: 0.152069\tvalid_0's gini: 0.276643\n",
            "Early stopping, best iteration is:\n",
            "[210]\tvalid_0's binary_logloss: 0.152007\tvalid_0's gini: 0.278406\n",
            "0.2784062320151674\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151774\tvalid_0's gini: 0.285887\n",
            "[200]\tvalid_0's binary_logloss: 0.151782\tvalid_0's gini: 0.285647\n",
            "Early stopping, best iteration is:\n",
            "[162]\tvalid_0's binary_logloss: 0.151746\tvalid_0's gini: 0.286161\n",
            "0.2861606126773889\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's binary_logloss: 0.151463\tvalid_0's gini: 0.290822\n",
            "[200]\tvalid_0's binary_logloss: 0.151373\tvalid_0's gini: 0.293373\n",
            "[300]\tvalid_0's binary_logloss: 0.151448\tvalid_0's gini: 0.29115\n",
            "Early stopping, best iteration is:\n",
            "[206]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.293699\n",
            "0.293699330308687\n",
            "cv score:\n",
            "0.286205194816888\n",
            "current score: 0.28860781830851967 22\n",
            "[0.29505891187734334, 0.2781424423117497, 0.2784062320151674, 0.2861606126773889, 0.293699330308687]\n",
            "[208, 258, 210, 162, 206] 208.8\n",
            "[0.2858393180467914, 0.2857025892457676, 0.2857014342774277, 0.28642219769508487, 0.28657299171180295, 0.2864549941342671, 0.2849306183737817, 0.28591254303953334, 0.2850760894090657, 0.28534116886916905, 0.28532266076273827, 0.28618096957698835, 0.2859750728807769, 0.28622141629497744, 0.2856714472163492, 0.2856285709657942, 0.2858530956858175, 0.2860702512738158, 0.28565408652314167, 0.28588450841345214, 0.28487583381291626, 0.286205194816888]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2At5fYwPJKx"
      },
      "source": [
        "pd.DataFrame({'id': test_id, 'target': final_cv_pred / 22.}).to_csv('lgbm_delcalc22.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdegX3JtyrQu"
      },
      "source": [
        "다시..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXZsbkOFys5V",
        "outputId": "c6e6648c-5839-4698-857f-2070e2f276da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "\n",
        "from scipy.stats.mstats import hmean\n",
        "\n",
        "lgbm = pd.read_csv('lgbm_delcalc22.csv')\n",
        "nn = pd.read_csv('nn_model_with_cv(del calc + inter).csv')\n",
        "preds = pd.concat([lgbm['target'], nn['target']])\n",
        "\n",
        "#Apply harmonic mean \n",
        "preds = preds.groupby(level=0).apply(hmean)\n",
        "\n",
        "# Create submission \n",
        "print(preds.head)\n",
        "sub = pd.DataFrame()\n",
        "sub['id'] = lgbm['id']\n",
        "sub['target'] = preds\n",
        "\t\n",
        "sub.to_csv('sub_harmonic(lgbm+nn)2.csv', index = False) \n",
        "\n",
        "#def get_rank(x):\n",
        " # return pd.Series(x).rank(pct=True).values\n",
        "\n",
        "#pd.DataFrame({'id':lgbm['id'],'target':get_rank(lgbm['target'])*0.5 + get_rank(nn['target'])*0.5}).to_csv('simple_average4.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of 0         0.054134\n",
            "1         0.043964\n",
            "2         0.043060\n",
            "3         0.021783\n",
            "4         0.066621\n",
            "            ...   \n",
            "892811    0.167522\n",
            "892812    0.084535\n",
            "892813    0.062941\n",
            "892814    0.039807\n",
            "892815    0.051672\n",
            "Name: target, Length: 892816, dtype: float64>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mF3c9sXyxLV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}